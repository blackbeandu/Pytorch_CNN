{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 이름 : \n# 학번 : \n--------------\n## Final Project \n\n### Project: Painting classification\n\n### Due date: 2021.06.17\n\n### 다음 링크로 접속하여 우선 팀 명을 바꿉니다. ex)20185141_용권순\nhttps://www.kaggle.com/competitions/2022-deep-learning-basics-challenge\n\n#### Data로 가서 Data를 모두 다운 받습니다. 그 다음은 Template code를 따라서 진행하시면 됩니다. \n>##### 최종실행 후  csv파일을 업로드 하시면 public결과가 보여집니다. \n\n---\n\n* 아래 여러 셀에서 코드를 완성하는 부분을 수행하고, 보고서에 설명을 최대한 자세하게 적어주세요. 기준은 본인이 이해하고 있다는 것을 표현할 수 있는 부분을 모두 적으시면 됩니다.\n  \n  \n> **제출방법**: \n* 보고서에는 코드 캡쳐 첨부이외에도, 각 코드를 작성하는 기반 이론, 방법론과 설명을 작성하세요.\n---------------------------","metadata":{"execution":{"iopub.execute_input":"2022-05-02T04:27:09.729446Z","iopub.status.busy":"2022-05-02T04:27:09.729037Z","iopub.status.idle":"2022-05-02T04:27:09.736951Z","shell.execute_reply":"2022-05-02T04:27:09.7359Z","shell.execute_reply.started":"2022-05-02T04:27:09.729396Z"}}},{"cell_type":"markdown","source":"## Final project 규칙\n\n- 학생들 간의 질문은 금지합니다 (교수 및 조교에게 질문하세요)\n- 대 원칙은 \"내가 이해한 것만 활용하고 작성한다\" 입니다\n- 사용하는 기법들과 코드는 모두 보고서에 설명되어야하며, 설명이 없는 경우 감점이나 0점 처리합니다\n    - 예를 들어서 검색한 끝에 model ensemble이라는 기법이 유용할 것 같아서, 참고하여 성능을 개선한 경우\n        1. 참고자료의 출처를 작성할 것\n        2. 기반 이론을 설명할 것\n        3. 사용한 코드 분석 및 기법을 설명할 것\n- 주석이 없는 경우 채점하지 않습니다\n- <p style=\"color:red;\">Pretrained network은 사용하지 않습니다. 본 프로젝트에서는, random 초기화한 parameter들을 직접 학습하는 과정만 허용합니다</p>\n\n    - 랜덤 초기화 기법은 특별한 제약이 없습니다\n- Competition 순위와 보고서는 각각 5:5로 점수가 반영됩니다.\n------------------------\n\n# 주의: 최종적으로 제출한 csv파일이 code에서 돌린 파일과 일치해야합니다. \n> + 기말 프로젝트 제출 시, model의 파라메터가 저장된 pt 파일, 보고서를 같이 제출합니다. \n> + 체점 과정 중 kaggle에 올라간 최종 csv파일과 제출한 모델을 사용하여 학생이 제출한 code로 csv생성 및 비교합니다(수기 변경 방지).\n> + kaggle에 올라간 최종 csv파일과 학생이 제출한 code로 생성한 csv파일이 다를 경우 감점 요소가 생길 수 있으니 주의해주시길 바랍니다.\n\n## 제출 하기 전 모든 셀을 정리해서 커널을 다시 실행하는 것을 권장 ","metadata":{}},{"cell_type":"markdown","source":"---\n","metadata":{}},{"cell_type":"markdown","source":"# 배경 설명\n\n> #### 여러분은 유명한 화가의 작품을 전시하는 유명한 미술관에 취업했습니다. \n>#### 최근 미술관이 대량의 작품을 입수하여, 각 화가들의 전시회를 열려고 합니다.   \n>#### 그러나 작품의 수가 너무나 많아서 사람이 분류하기에는 시간이 오래 걸릴것이라고 판단됩니다. \n>#### 이에 여러분은 딥러닝을 사용하여 효율적인 화가별 그림 분류 프로그램을 만들고자 합니다.\n\n# 목표: \n> ### 본 프로젝트의 완성본은, 새로운 그림(Image)입력하면 <p style=\"color:red\">해당 그림을 그린 화가를 예측합니다.</p>\n\n","metadata":{}},{"cell_type":"markdown","source":"-------------------------------\n------------------------------\n-----------------------------","metadata":{}},{"cell_type":"markdown","source":"## Step 0: Import library\n\n- 필요하다 생각되는 라이브러리를 미리 import합니다. (참고)\n- 필요 없는 라이브러리를 제거하거나 필요한 라이브러리를 추가하셔도 됩니다.","metadata":{}},{"cell_type":"code","source":"import os\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm, trange\nimport random\nimport pandas as pd\nfrom PIL import Image\nfrom pathlib import Path\nfrom collections import OrderedDict\nfrom time import time, ctime, localtime\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data import Dataset,DataLoader\n\nimport torchvision\nimport torchvision.transforms as transforms\n\nfrom torchvision import datasets\nfrom torchvision import models\n\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split,train_test_split\nfrom sklearn.model_selection import StratifiedKFold,  KFold\n","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:16:42.814688Z","iopub.execute_input":"2022-06-17T12:16:42.815099Z","iopub.status.idle":"2022-06-17T12:16:45.549644Z","shell.execute_reply.started":"2022-06-17T12:16:42.814976Z","shell.execute_reply":"2022-06-17T12:16:45.548903Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"-----------------------------------","metadata":{}},{"cell_type":"markdown","source":"## Step 1: Preparing Dataset \n### 1-1: 경로 설정","metadata":{}},{"cell_type":"code","source":"#본인 컴퓨터에 맞는 train folder의 위치를 입력합니다.(string)\ntrain_dir = '../input/2022-deep-learning-basics-challenge/painting_resize_256/train'   ","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:16:45.551139Z","iopub.execute_input":"2022-06-17T12:16:45.551662Z","iopub.status.idle":"2022-06-17T12:16:45.554648Z","shell.execute_reply.started":"2022-06-17T12:16:45.551623Z","shell.execute_reply":"2022-06-17T12:16:45.553992Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# 폴더의 목록(화가의 이름)을 가지고 옵니다. 총 class : 15개  \nclasses = []\n#class목록을 저장할 list \nfor i in range(len(glob.glob(train_dir+'/*'))):\n    classes.append(glob.glob(train_dir+'/*')[i].split('/')[-1])\nclass_num = len(classes)\nprint('Total Class num: ',class_num)\nprint('Class label:')\nfor i in range(class_num):print('{:5d}th : ' .format(i+1),classes[i])\n#glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다.\n#기존 양식 코드 그대로 사용.","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:16:45.555996Z","iopub.execute_input":"2022-06-17T12:16:45.556384Z","iopub.status.idle":"2022-06-17T12:16:45.584784Z","shell.execute_reply.started":"2022-06-17T12:16:45.556350Z","shell.execute_reply":"2022-06-17T12:16:45.584144Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### 1-2. 제대로 read 되는지 확인 (Transform적용)","metadata":{}},{"cell_type":"code","source":"classes = sorted(classes)\nclasses","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:16:45.586345Z","iopub.execute_input":"2022-06-17T12:16:45.586600Z","iopub.status.idle":"2022-06-17T12:16:45.594071Z","shell.execute_reply.started":"2022-06-17T12:16:45.586567Z","shell.execute_reply":"2022-06-17T12:16:45.593351Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def check_Image(image_path,transform =None):\n    image = Image.open(image_path).convert(\"RGB\") #해당 경로의 image를 RGB순서로 변환\n    if transform ==None: #transform이 없으면 그대로 image 반환\n        return image\n    else: return transform(image) #transform이 있으면 적용 후 image 반환","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:16:45.595442Z","iopub.execute_input":"2022-06-17T12:16:45.596022Z","iopub.status.idle":"2022-06-17T12:16:45.602857Z","shell.execute_reply.started":"2022-06-17T12:16:45.595913Z","shell.execute_reply":"2022-06-17T12:16:45.601322Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"image = \"../input/2022-deep-learning-basics-challenge/painting_resize_256/train/Andy_Warhol/Andy_Warhol_1.jpg\"\ncheck_Image(image)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:16:45.922779Z","iopub.execute_input":"2022-06-17T12:16:45.923428Z","iopub.status.idle":"2022-06-17T12:16:45.977713Z","shell.execute_reply.started":"2022-06-17T12:16:45.923390Z","shell.execute_reply":"2022-06-17T12:16:45.976973Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#image가 어떤 식으로 transform 되는지 확인하고 싶을 때 사용하시면 됩니다. \n# transform = transforms.Compose([transforms.RandomEqualize()])\ntransform = transforms.Compose([transforms.RandomPosterize(bits=2, p=0.5)])\ncheck_Image(image,transform)\n#,transforms.RandomEqualize(p=0.5)\n#  transforms.RandomPosterize(bits=2, p=0.5),\n#                                       transforms.RandomEqualize(p=0.5), #주어진 확률로 무작위로 주어진 이미지의 히스토그램을 균등화한다.","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:16:48.279354Z","iopub.execute_input":"2022-06-17T12:16:48.279615Z","iopub.status.idle":"2022-06-17T12:16:48.330847Z","shell.execute_reply.started":"2022-06-17T12:16:48.279586Z","shell.execute_reply":"2022-06-17T12:16:48.330203Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([transforms.Grayscale(1)])\ncheck_Image(image,transform)\n#transform이 제대로 적용되는지 확인한다.","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:16:48.677301Z","iopub.execute_input":"2022-06-17T12:16:48.678163Z","iopub.status.idle":"2022-06-17T12:16:48.696623Z","shell.execute_reply.started":"2022-06-17T12:16:48.678123Z","shell.execute_reply":"2022-06-17T12:16:48.695939Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Step2: Generating DataLoader for Dataset","metadata":{}},{"cell_type":"code","source":"#데이터 셋에 대한 평균과 표준편차 구하기\ndata_dir = \"../input/2022-deep-learning-basics-challenge/painting_resize_256\" #데이터 셋 경로\ntrain_ds_transform = transforms.Compose([transforms.ToTensor()]) #데이터를 오직 텐서화만 진행할 예정\ntrain_ds = datasets.ImageFolder(data_dir+'/train', transform = train_ds_transform) #데이터 셋 텐서화 진행\n\n\nmeanRGB = [np.mean(x.numpy(), axis=(1,2)) for x,_ in train_ds] \n#train_ds에 x(이미지데이터)만 사용 _는 lable이라 불필요하다.\n#numpy함수를 이용하여 평균을 구한다. train_ds는 채널을 가진 3차원이다. axis를 튜플로 줄 경수 순서대로 진행한다.\n#행에 따라 합한뒤 열에따라 합한 후 평균을 구한다.\nstdRGB = [np.std(x.numpy(), axis=(1,2)) for x,_ in train_ds]\n#표준편차도 평균과 동일하게 구한다.\n\n\nmeanR = np.mean([m[0] for m in meanRGB])\n#0번째 index에는 R에 대한 값이 들어있고 R의 평균값을 구한다.\nmeanG = np.mean([m[1] for m in meanRGB])\n#1번째 index에는 G에 대한 값이 들어있고 R의 평균값을 구한다.\nmeanB = np.mean([m[2] for m in meanRGB])\n#2번째 index에는 B에 대한 값이 들어있고 R의 평균값을 구한다.\n\nstdR = np.mean([s[0] for s in stdRGB])\nstdG = np.mean([s[1] for s in stdRGB])\nstdB = np.mean([s[2] for s in stdRGB])\n#평균과 설명이 동일하다.\n\n#데이터 전체에 대한 일반화된 값을 구해야 하므로 평균과 표준편차도 각각에 대한 평균으로 구한다.\n\n\nprint(meanR, meanG, meanB)\nprint(stdR, stdG, stdB)\n# 0.5200497 0.4652539 0.39320767\n# 0.20736203 0.19569875 0.1818195","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:16:49.118379Z","iopub.execute_input":"2022-06-17T12:16:49.118919Z","iopub.status.idle":"2022-06-17T12:17:22.564054Z","shell.execute_reply.started":"2022-06-17T12:16:49.118880Z","shell.execute_reply":"2022-06-17T12:17:22.562528Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#model_A 에 관한 데이터 셋\ndata_dir = \"../input/2022-deep-learning-basics-challenge/painting_resize_256\"\n#transforms.RandomRotation(30),transforms.RandomInvert(p=0.5),#p=0.5\n#transforms.RandomRotation(30), #랜덤으로 회전시킨다. 현재 0~30도.\n#train_data에 대한 transform\n#여러 transform들을 활용하기 위해 Compose를 사용한다.\ntrain_transform_A = transforms.Compose([\n                                      transforms.RandomCrop(244), #랜덤한 위치에서 244*244만큼 자른다.\n                                      transforms.RandomHorizontalFlip(p=0.5), #주어진 확률값으로 수평으로 뒤집는다. 현재 50%\n                                      transforms.RandomVerticalFlip(p=0.5), #주어진 확률값으로 수직으로 뒤집는다. 현재 50%\n                                      transforms.ToTensor(), #데이터 텐서화.\n                                      transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])]) #텐서 이미지 정규화.\n                                      #input[channel] = (input[channel] - mean[channel]) / std[channel]공식에 의해 RGB가 normalize된다.\n\n#valid_data에 대한 transform\nvalid_transform_A = transforms.Compose([\n                                      transforms.CenterCrop(244), #가운데에서 244*244만큼 자른다\n                                      transforms.ToTensor(),#데이터 텐서화.\n                                      transforms.Normalize([meanR, meanG, meanB ], [stdR, stdG, stdB])])#텐서 이미지 정규화.\n\n\n\n\n\n#폴더 구조를 가지고 있는 데이터셋을 불러올 때 ImageFolder를 사용한다.\n#transform에는 내가 만든 transfrom을 대입해 이미지에 변화를 줄 수 있다.\n#해당 경로의 ImageFolder data에 transform을 적용한다.\ntrain_data_A = datasets.ImageFolder(data_dir+'/train', transform = train_transform_A)\nvalid_data_A = datasets.ImageFolder(data_dir+'/train', transform = valid_transform_A)\n\n\n\nval_size = 0.2 #valid_data의 크기를 20%로 설정\nnum_train = len(train_data_A) #train_data_A에 길이(크기) 구하기\nnum_train = int(num_train) #int로 형변환한다. 소수점은 버린다.\nindices = list(range(num_train)) #길이만큼 index부여하면서 list생성한다. indices = [0 ~ int(num_train)-1]\nnp.random.shuffle(indices) #indices를 랜덤으로 섞는다.\nsplit = int(np.floor(val_size * num_train)) # np.floor은 내림함수이다. 8:2로 나누기 위해 구간을 정한다.\ntrain_idx, valid_idx = indices[split:], indices[:split] #train_dix는 20~99, valide_idx는 0~19만큼 가진다.\n\n#SubsetRandomSampler 주어진 인덱스 목록에서 요소를 무작위로 샘플링\n#dataset의 일정 부분을 나눠서 사용할 수 있다.\ntrain_sampler_A = SubsetRandomSampler(train_idx)\nvalid_sampler_A = SubsetRandomSampler(valid_idx)\n\ntrain_loader_A = torch.utils.data.DataLoader(train_data_A, batch_size=16, sampler = train_sampler_A)\nvalid_loader_A = torch.utils.data.DataLoader(valid_data_A, batch_size=16, sampler = valid_sampler_A)\n#dataset=train(valid)_data_A, batch_size=16, samper = train(valid)_sampler_A\n\n\nprint(len(train_loader_A))\nprint(len(valid_loader_A))\n#train_loader_A와 valid_loader_A를 batch_size로 구분 했을 때의 길이를 출력해본다.\n","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:17:22.566002Z","iopub.execute_input":"2022-06-17T12:17:22.566255Z","iopub.status.idle":"2022-06-17T12:17:22.636963Z","shell.execute_reply.started":"2022-06-17T12:17:22.566219Z","shell.execute_reply":"2022-06-17T12:17:22.636190Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#model_B\ndata_dir = \"../input/2022-deep-learning-basics-challenge/painting_resize_256\"\n\ntrain_transform_B = transforms.Compose([\n                                      transforms.CenterCrop(244), #가운데에서 244*244로 자른다.\n                                      transforms.RandomHorizontalFlip(p=0.5), #주어진 확률로 수평으로 뒤집는다.\n                                      transforms.RandomRotation(90),#임의의 각도로 이미지를 회전한다. (0~90)\n                                      transforms.ToTensor(), #데이터 텐서화\n                                      transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])])#텐서 이미지 정규화\n#transforms.Resize(255),\nvalid_transform_B = transforms.Compose([\n                                      transforms.CenterCrop(244),#가운데에서 244*244로 자른다.\n                                      transforms.ToTensor(),#데이터 텐서화\n                                      transforms.Normalize([meanR, meanG, meanB ], [stdR, stdG, stdB])])#텐서 이미지 정규화\n\n\n#폴더 구조를 가지고 있는 데이터셋을 불러올 때 ImageFolder를 사용한다.\n#transform에는 내가 만든 transfrom을 대입해 이미지에 변화를 줄 수 있다.\n#해당 경로의 ImageFolder data에 transform을 적용한다.\ntrain_data_B = datasets.ImageFolder(data_dir+'/train', transform = train_transform_B)\nvalid_data_B = datasets.ImageFolder(data_dir+'/train', transform = valid_transform_B)\n\n\nval_size = 0.2 #valid_data의 크기를 20%로 설정\nnum_train = len(train_data_B) #train_data_B에 길이(크기) 구하기\nnum_train = int(num_train) #int로 형변환한다. 소수점은 버린다.\nindices = list(range(num_train)) #길이만큼 index부여하면서 list생성한다. indices = [0 ~ int(num_train)-1]\nnp.random.shuffle(indices) #indices를 랜덤으로 섞는다.\nsplit = int(np.floor(val_size * num_train)) # np.floor은 내림함수이다. 8:2로 나누기 위해 구간을 정한다.\ntrain_idx, valid_idx = indices[split:], indices[:split] #train_dix는 20~99, valide_idx는 0~19만큼 가진다.\n\n#SubsetRandomSampler 주어진 인덱스 목록에서 요소를 무작위로 샘플링\n#dataset의 일정 부분을 나눠서 사용할 수 있다.\ntrain_sampler_B = SubsetRandomSampler(train_idx)\nvalid_sampler_B = SubsetRandomSampler(valid_idx)\n\n\ntrain_loader_B = torch.utils.data.DataLoader(train_data_B, batch_size=16, sampler = train_sampler_B)\nvalid_loader_B = torch.utils.data.DataLoader(valid_data_B, batch_size=16, sampler = valid_sampler_B)\n#dataset=train(valid)_data_B, batch_size=16, samper = train(valid)_sampler_B\n\n\nprint(len(train_loader_B))\nprint(len(valid_loader_B))\n#train_loader_B와 valid_loader_B를 batch_size로 구분 했을 때의 길이를 출력해본다.","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:17:22.638719Z","iopub.execute_input":"2022-06-17T12:17:22.639299Z","iopub.status.idle":"2022-06-17T12:17:22.712854Z","shell.execute_reply.started":"2022-06-17T12:17:22.639258Z","shell.execute_reply":"2022-06-17T12:17:22.712185Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#model_C\ndata_dir = \"../input/2022-deep-learning-basics-challenge/painting_resize_256\"\n#transforms.RandomRotation(30),transforms.RandomInvert(p=0.5),#p=0.5\n#transforms.RandomEqualize(p=0.5), #주어진 확률로 무작위로 주어진 이미지의 히스토그램을 균등화한다.\n# transforms.RandomAdjustSharpness(sharpness_factor=2),#주어진 이미지의 선명도를 무작위로 조정한다. sharpness_factor는 선명도를 조절항 정도이다. 음수는 불가능.\ntrain_transform_C = transforms.Compose([\n                                      transforms.CenterCrop(244),\n                                      transforms.RandomHorizontalFlip(p=0.5),\n                                      transforms.RandomEqualize(),\n                                      transforms.ToTensor(),#데이터 텐서화\n                                      transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])])#텐서 이미지 정규화\n\nvalid_transform_C = transforms.Compose([\n                                      transforms.CenterCrop(244),#가운데에서 244*244로 자른다.\n                                      transforms.ToTensor(),#데이터 텐서화\n                                      transforms.Normalize([meanR, meanG, meanB ], [stdR, stdG, stdB])])#텐서 이미지 정규화\n\n\n\n#폴더 구조를 가지고 있는 데이터셋을 불러올 때 ImageFolder를 사용한다.\n#transform에는 내가 만든 transfrom을 대입해 이미지에 변화를 줄 수 있다.\n#해당 경로의 ImageFolder data에 transform을 적용한다.\ntrain_data_C = datasets.ImageFolder(data_dir+'/train', transform = train_transform_C)\nvalid_data_C = datasets.ImageFolder(data_dir+'/train', transform = valid_transform_C)\n\n\nval_size = 0.2 #valid_data의 크기를 20%로 설정\nnum_train = len(train_data_C) #train_data_B에 길이(크기) 구하기\nnum_train = int(num_train) #int로 형변환한다. 소수점은 버린다.\nindices = list(range(num_train)) #길이만큼 index부여하면서 list생성한다. indices = [0 ~ int(num_train)-1]\nnp.random.shuffle(indices) #indices를 랜덤으로 섞는다.\nsplit = int(np.floor(val_size * num_train)) # np.floor은 내림함수이다. 8:2로 나누기 위해 구간을 정한다.\ntrain_idx, valid_idx = indices[split:], indices[:split] #train_dix는 20~99, valide_idx는 0~19만큼 가진다.\n\n\n#SubsetRandomSampler 주어진 인덱스 목록에서 요소를 무작위로 샘플링\n#dataset의 일정 부분을 나눠서 사용할 수 있다.\ntrain_sampler_C = SubsetRandomSampler(train_idx)\nvalid_sampler_C = SubsetRandomSampler(valid_idx)\n\n\ntrain_loader_C = torch.utils.data.DataLoader(train_data_C, batch_size=16, sampler = train_sampler_C)\nvalid_loader_C = torch.utils.data.DataLoader(valid_data_C, batch_size=16, sampler = valid_sampler_C)\n#dataset=train(valid)_data_C, batch_size=16, samper = train(valid)_sampler_C\n\n\nprint(len(train_loader_C))\nprint(len(valid_loader_C))\n#train_loader_B와 valid_loader_B를 batch_size로 구분 했을 때의 길이를 출력해본다.","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:17:22.714996Z","iopub.execute_input":"2022-06-17T12:17:22.715481Z","iopub.status.idle":"2022-06-17T12:17:22.788190Z","shell.execute_reply.started":"2022-06-17T12:17:22.715431Z","shell.execute_reply":"2022-06-17T12:17:22.787249Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"--------------------------","metadata":{"execution":{"iopub.execute_input":"2022-05-02T07:16:33.271344Z","iopub.status.busy":"2022-05-02T07:16:33.271002Z","iopub.status.idle":"2022-05-02T07:16:33.277614Z","shell.execute_reply":"2022-05-02T07:16:33.276446Z","shell.execute_reply.started":"2022-05-02T07:16:33.271298Z"}}},{"cell_type":"markdown","source":"## Step 3: Generating Neural Network(model) \n - <p style=\"color:red;\">Pretrained network은 사용하지 않습니다. 본 프로젝트에서는, random 초기화한 parameter들을 직접 학습하는 과정만 허용합니다</p>\n - 모델을 선정한 이유를 간략하게 정리합니다.","metadata":{}},{"cell_type":"code","source":"class GNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        #input  3*244*244\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride = 1, padding=1)\n        #input채널이 3, output채널을 64로 설정.  kernel_size=3으로 설정. 필터(kerndel) 이동거리는 1(stride=1)\n        #padding=1로 원래 채널의 테두리에 한칸이 늘어나며 값은 0으로 들어간다.\n        self.conv1_bn = nn.BatchNorm2d(64)\n        #2d배치 정규화로 output 채널값을 num_features에 받는다.\n        #더 쉽게 train가능하게 해주며 gradient의 흐름을 향상시킨다.\n        \n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride = 1, padding=1)\n        self.conv2_bn = nn.BatchNorm2d(128)\n        \n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride = 1, padding=1)\n        self.conv3_bn = nn.BatchNorm2d(256)\n        \n        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride = 1, padding=1)\n        self.conv4_bn = nn.BatchNorm2d(512)\n        \n        self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, stride = 1, padding=1)\n        self.conv5_bn = nn.BatchNorm2d(1024)\n        \n        self.conv6 = nn.Conv2d(1024, 2048, kernel_size=3, stride = 1, padding=1)\n        self.conv6_bn = nn.BatchNorm2d(2048)\n        \n        \n        \n        self.pool = nn.MaxPool2d((2,2) , stride=2) \n        #kernel_size = (2,2)로 해당 필터 안에 최대 값을 가져온다.\n        #stride =2로 채널의 이동거리이다. MaxPool2d를 이와 같이 설정하면 한 층이 지나면 출력값이 1/2로 줄어든다.\n        \n        self.fc1 = nn.Linear(2048*3*3, 512)\n        self.fc1_bn = nn.BatchNorm1d(512)\n        #1d배치 정규화로 output값을 num_feature에 받는다.\n        \n        self.fc2 = nn.Linear(512, 15)\n        \n        self.dropout = nn.Dropout(0.5) \n        #신경망의 과적합을 줄이기 위한 대표적인 정규화 기술. 뉴런의 일부를 0으로대치하여 계산에서 제외한다.\n        #0.2~0.5가 통상 \n        \n        self.relu = nn.ReLU(True)\n        #max(0,x)를 의미하는 함수로 0보다 작으면 0이 되는 특징을 가지고 있다.\n        #0이하의 입력에 대해 0을 출력함으로써 부분적으로 활성화가 가능하며 선형함수이므로 미분 계산이 매우 편리하다.\n        \n    def forward(self, x):\n        x = self.pool(self.relu(self.conv1_bn(self.conv1(x))))\n        x = self.pool(self.relu(self.conv2_bn(self.conv2(x))))\n\n        x = self.pool(self.relu(self.conv3_bn(self.conv3(x))))\n        x = self.pool(self.relu(self.conv4_bn(self.conv4(x))))\n        \n        x = self.pool(self.relu(self.conv5_bn(self.conv5(x))))\n        x = self.pool(self.relu(self.conv6_bn(self.conv6(x))))\n        #컨볼루션 -> 배치 정규화 -> activation func -> pooling\n        \n        x = x.view(-1,2048*3*3)\n        #데이터 flatten\n\n        x = self.relu(self.fc1_bn(self.fc1(x)))\n        x = self.dropout(x)\n        \n        x = self.fc2(x)\n        \n        return x\n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:17:22.789856Z","iopub.execute_input":"2022-06-17T12:17:22.790163Z","iopub.status.idle":"2022-06-17T12:17:22.808887Z","shell.execute_reply.started":"2022-06-17T12:17:22.790129Z","shell.execute_reply":"2022-06-17T12:17:22.807978Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"--------------------------","metadata":{"execution":{"iopub.execute_input":"2022-05-02T07:16:33.271344Z","iopub.status.busy":"2022-05-02T07:16:33.271002Z","iopub.status.idle":"2022-05-02T07:16:33.277614Z","shell.execute_reply":"2022-05-02T07:16:33.276446Z","shell.execute_reply.started":"2022-05-02T07:16:33.271298Z"}}},{"cell_type":"markdown","source":"## Step 4: Selecting Cost(Loss) Function & Optimizer\n> +  [loss function](http://pytorch.org/docs/stable/nn.html#loss-functions) 및 [optimizer](http://pytorch.org/docs/stable/optim.html)를 선택하여 코드를 완성하세요.\n  링크에서 다양한 Loss Function과 Optimize Function을 확인 할 수 있습니다","metadata":{}},{"cell_type":"code","source":"device = 'cpu'\nif torch.cuda.is_available():\n    device = 'cuda'\n\nmodel_A = GNN()\n\nmodel_B = GNN()\n\nmodel_C = GNN()\n#모델 3개 선언 -> 앙상블 기법을 활용하기 위함.\n#스케줄러와 데이터 셋 transform에 차이가 있다.\n\nnSamples = [19,262,210,702,72,\n            114,67,233,562,351,\n            145,82,269,58,191] #not sort\n#각 클래스별 데이터 개수이며 기존 클래스 출력시 나온 순서대로 넣었다.\n\n# nSamples = [262,145,58,562,72,233,19,82,114,191,351,269,67,210,702] #sort\n\n\n# normedWeights1 = [1 - (x / sum(nSamples)) for x in nSamples] \n#처음에 가중치를 이렇게 조절했는데 적은 데이터를 가지는 클래스와 많은 데이터를 가지는 클래스와 큰 차이가 없었다. \n#이를 토대로 직접 가중치를 설정했다.\n# normedWeights1 = [(1 / (x*10)) for x in nSamples] #loss는 적은데 acc도 잘 안오름 최대 약 60정\nnormedWeights1 = [0.99, 0.7, 0.7, 0.4, 0.97, \n                  0.85, 0.99, 0.7, 0.5, 0.6, \n                  0.8, 0.97, 0.7, 0.99, 0.8]\nnormedWeights2 = torch.FloatTensor(normedWeights1).to(device)\n#가중치를 float형 텐서로 변환했다.\n#클래스 불균형이 매우 심하기 때문에 적용했다.\n\n\n\ncriterion_A = nn.CrossEntropyLoss(normedWeights2)\ncriterion_B = nn.CrossEntropyLoss(normedWeights2)\ncriterion_C = nn.CrossEntropyLoss(normedWeights2)\n\n#각 모델에 대한 CrossEntropyLoss이며 동일하게 가중치를 대입했다.\n\n\n\noptimizer_A = optim.Adam(model_A.parameters(), lr = 0.0001, weight_decay=0.00001)\nscheduler_A = optim.lr_scheduler.MultiStepLR(optimizer_A, milestones=[15,30,45], gamma=0.1, last_epoch=- 1, verbose=True)\n#model_A의 파라미터를 받으며 learning rate = 1e-4, weight_decay = 1e-5로 설정했다.\n#MultiStepLR learnig rate를 감소시킬 epoch을 정해준다. 감소량은 lr= gamma*lr \n#last_epoch은 학습을 다시 시작할 때 이전에 중단된 스케줄러를 시작하려 하는데 -1이면 스케줄러가 처음부터 시작되었음을 나타낸다.\n#verbose = True로 lr의 변동된 값을 확인할 수 있다.\n\noptimizer_B = optim.Adam(model_B.parameters(), lr = 0.0001, weight_decay=0.00001)\n#model_B의 파라미터를 받으며 learning rate = 1e-4, weight_decay = 1e-5로 설정했다.\nscheduler_B = optim.lr_scheduler.LambdaLR(optimizer=optimizer_B,\n                                        lr_lambda=lambda epoch: 0.95 ** epoch,\n                                        last_epoch=-1,\n                                        verbose=True)\n#LambdaLR 초기 learning_rate에 lambda함수에서 나온 값을 곱해서 learning_rate를 계산한다.\n#last_epoch은 학습을 다시 시작할 때 이전에 중단된 스케줄러를 시작하려 하는데 -1이면 스케줄러가 처음부터 시작되었음을 나타낸다.\n#verbose = True로 lr의 변동된 값을 확인할 수 있다.\n\n\noptimizer_C = optim.Adam(model_C.parameters(), lr = 0.0001, weight_decay=0.00001)\n#model_C의 파라미터를 받으며 learning rate = 1e-4, weight_decay = 1e-5로 설정했다.\nscheduler_C = optim.lr_scheduler.MultiStepLR(optimizer_C, milestones=[15,30,45], gamma=0.1, last_epoch=- 1, verbose=True)\n#MultiStepLR learnig rate를 감소시킬 epoch을 정해준다. 감소량은 lr= gamma*lr\n#last_epoch은 학습을 다시 시작할 때 이전에 중단된 스케줄러를 시작하려 하는데 -1이면 스케줄러가 처음부터 시작되었음을 나타낸다.\n#verbose = True로 lr의 변동된 값을 확인할 수 있다.\n\n\nmodel_A.to(device)\nmodel_B.to(device)\nmodel_C.to(device)\n#각 모델을 cuda에 올린다.\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:17:22.810304Z","iopub.execute_input":"2022-06-17T12:17:22.810776Z","iopub.status.idle":"2022-06-17T12:17:26.886882Z","shell.execute_reply.started":"2022-06-17T12:17:22.810733Z","shell.execute_reply":"2022-06-17T12:17:26.886191Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"--------------------------","metadata":{"execution":{"iopub.execute_input":"2022-05-02T07:16:33.271344Z","iopub.status.busy":"2022-05-02T07:16:33.271002Z","iopub.status.idle":"2022-05-02T07:16:33.277614Z","shell.execute_reply":"2022-05-02T07:16:33.276446Z","shell.execute_reply.started":"2022-05-02T07:16:33.271298Z"}}},{"cell_type":"markdown","source":"## Step 5: Train and validate the configured model\n### 학습 및 검증 과정을 진행합니다\n+ 학습 과정을 주석으로 설명하세요 \n+ Epoch별로 Loss, Accuracy를 출력하여 학습 진행 과정을 확인 할 수 있도록 합니다\n+ 출력 예시는 주어지나 정해진 형식은 없습니다\n+ 최적의 모델 파라메터를 저장합니다.\n\nFor example : \n```python\nStarted Training...\nEpoch: 1    Training Loss: 3.317162     Validation Loss: 4.162958\nEpoch: 2    Training Loss: 2.420140     Validation Loss: 4.182362\n...\n...\nFinished training\n```","metadata":{}},{"cell_type":"code","source":"n_epochs = 60 #에폭 수 60\n\nvalid_loss_min = np.Inf #valid_loss를 무한으로 주고 내려갈때 마다 저장한다.\n\ntrain_loss = torch.zeros(n_epochs) #에폭 수 만큼 0으로 채운 텐서 만들기 train_loss를 가질 예정이며 나중에 그래프 그릴 때 사용한다.\nvalid_loss = torch.zeros(n_epochs) #에폭 수 만큼 0으로 채운 텐서 만들기 valid_loss를 가질 예정이며 나중에 그래프 그릴 때 사용한다.\n\ntrain_acc = torch.zeros(n_epochs) #에폭 수 만큼 0으로 채운 텐서 만들기 train_acc를 가질 예정이며 나중에 그래프 그릴 때 사용한다.\nvalid_acc = torch.zeros(n_epochs) #에폭 수 만큼 0으로 채운 텐서 만들기 valid_acc를 가질 예정이며 나중에 그래프 그릴 때 사용한다.\n\n\nfor e in range(0, n_epochs):\n        model_A.train() #model_A학습 시작\n        for data, labels in train_loader_A:\n            data, labels = data.to(device), labels.to(device)\n            #data, labels를 cuda로 이동\n\n            optimizer_A.zero_grad()\n            #파라미터를 업데이트 한 후 새로운 batch에 대한 새 gradient를 계산해야 하기 때문에 옵티마이저를 초기화한다.\n            \n            logits = model_A(data) #data를 model_A에 넣어 결과 예측(계산)\n            \n            loss = criterion_A(logits, labels)#batch loss 계산\n            \n            loss.backward() #전체 파라미터에 대한 gradient를 구한다.\n            optimizer_A.step()  #gradient를 각 파라미터에 적용한다.\n\n            train_loss[e] += loss.item() #loss를 에폭 위치에 넣어준다.\n\n            ps = F.softmax(logits, dim=1) #logits값에 softmax를 취해 0과 1사이의 값으로 바뀐다.\n            top_p, top_class = ps.topk(1, dim=1) #주어진 input 텐서의 가장 큰 값 1개를 반환한다.\n            equals = top_class == labels.reshape(top_class.shape) #labels의 shape을 top_class의 shape으로 reshape한 후, top_class와 비교한다.\n            train_acc[e] += torch.mean(equals.type(torch.float)).item() #True, False를 float형 토치로 변환 후 평균을 에폭 index에 넣어준다.\n\n        train_loss[e] /= len(train_loader_A) #batch_size로 정해진 train_loader_A길이(크기)로 나눈다.\n        train_acc[e] /= len(train_loader_A)\n\n        with torch.no_grad():\n            model_A.eval() #validation 과정에서 사용하지 않을 layer들을 off(dropout 등)\n            for data, labels in valid_loader_A:\n                data, labels = data.to(device), labels.to(device)\n\n                logits = model_A(data) #data를 model_A에 넣어 결과 예측(계산)\n                loss = criterion_A(logits, labels) #batch loss 계산\n                valid_loss[e] += loss.item() #loss를 에폭 위치에 넣어준다.\n\n                ps = F.softmax(logits, dim=1) #logits값에 softmax를 취해 0과 1사이의 값으로 바뀐다.\n                top_p, top_class = ps.topk(1, dim=1) #주어진 input 텐서의 가장 큰 값 1개를 반환한다.\n                equals = top_class == labels.reshape(top_class.shape) #labels의 shape을 top_class의 shape으로 reshape한 후, top_class와 비교한다.\n                valid_acc[e] += torch.mean(equals.type(torch.float)).item() #True, False를 float형 토치로 변환 후 평균을 에폭 index에 넣어준다.\n\n        valid_loss[e] /= len(valid_loader_A) #batch_size로 정해진 valid_loader_A길이(크기)로 나눈다.\n        valid_acc[e] /= len(valid_loader_A)\n        scheduler_A.step()# 옵티마이저 매개 변수 업데이트(최적화) 단계\n        \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            e, train_loss[e], valid_loss[e]))\n        #train_loss와 valid_loss를 epoch마다 출력\n        \n        print('Epoch: {} \\tTraining accuracy: {:.6f} \\tValidation accuracy: {:.6f}'.format(\n            e, train_acc[e], valid_acc[e]))\n        #train_acc와 valid_acc를 epoch마다 출력\n        \n        #loss가 감소하면 state_dict저장. early stopping\n        if valid_loss_min > valid_loss[e]:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss[e]))\n            validpoint_A = {'model_state_dict': model_A.state_dict(),\n                  'optimizer_state_dict': optimizer_A.state_dict()}\n            #딕셔너리 타입으로 저장\n            torch.save(validpoint_A, 'validpoint_A.pth')\n\n            valid_loss_min = valid_loss[e] #valid_loss 갱신","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:17:26.888270Z","iopub.execute_input":"2022-06-17T12:17:26.888666Z","iopub.status.idle":"2022-06-17T12:44:03.045042Z","shell.execute_reply.started":"2022-06-17T12:17:26.888630Z","shell.execute_reply":"2022-06-17T12:44:03.044232Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_loss, label='train_loss')\nplt.plot(valid_loss, label='valid_loss')\nplt.legend()\n#train_loss와 valid_loss를 그래프로 출력한다.","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:44:03.046188Z","iopub.execute_input":"2022-06-17T12:44:03.046570Z","iopub.status.idle":"2022-06-17T12:44:03.309558Z","shell.execute_reply.started":"2022-06-17T12:44:03.046516Z","shell.execute_reply":"2022-06-17T12:44:03.308621Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_acc, label='train_acc')\nplt.plot(valid_acc, label='valid_acc')\nplt.legend()\n#train_acc와 valid_acc를 그래프로 출력한다.\n#train_acc는 계속 상승하는데 valid_acc는 증가하다 점점 감소하다면 그 구간(epoch)부터 overfitting으로 간주한다.\n#train_acc와 valid_acc의 간격이 큰 차이가 없으며 성능이 올라간다면 underfitting으로 간주한다.","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:44:03.311112Z","iopub.execute_input":"2022-06-17T12:44:03.311370Z","iopub.status.idle":"2022-06-17T12:44:03.525688Z","shell.execute_reply.started":"2022-06-17T12:44:03.311333Z","shell.execute_reply":"2022-06-17T12:44:03.524570Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"n_epochs = 60\n\nvalid_loss_min = np.Inf\nvalid_acc_min = 0\n\ntrain_loss = torch.zeros(n_epochs)\nvalid_loss = torch.zeros(n_epochs)\n\ntrain_acc = torch.zeros(n_epochs)\nvalid_acc = torch.zeros(n_epochs)\n\n\nfor e in range(0, n_epochs):\n        model_B.train()\n        for data, labels in train_loader_B:\n            data, labels = data.to(device), labels.to(device)\n\n            optimizer_B.zero_grad()\n\n            logits = model_B(data)\n            loss = criterion_B(logits, labels)\n            loss.backward()\n            optimizer_B.step()\n\n            train_loss[e] += loss.item()\n\n            ps = F.softmax(logits, dim=1)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == labels.reshape(top_class.shape)\n            train_acc[e] += torch.mean(equals.type(torch.float)).item()\n\n        train_loss[e] /= len(train_loader_B)\n        train_acc[e] /= len(train_loader_B)\n\n        with torch.no_grad():\n            model_B.eval()\n            for data, labels in valid_loader_B:\n                data, labels = data.to(device), labels.to(device)\n\n                logits = model_B(data)\n                loss = criterion_B(logits, labels)\n                valid_loss[e] += loss.item()\n\n                ps = F.softmax(logits, dim=1)\n                top_p, top_class = ps.topk(1, dim=1) #logits 이었던거 같은데\n                equals = top_class == labels.reshape(top_class.shape)\n                valid_acc[e] += torch.mean(equals.type(torch.float)).item()\n\n        valid_loss[e] /= len(valid_loader_B)\n        valid_acc[e] /= len(valid_loader_B)\n        scheduler_B.step()\n        \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            e, train_loss[e], valid_loss[e]))\n\n        print('Epoch: {} \\tTraining accuracy: {:.6f} \\tValidation accuracy: {:.6f}'.format(\n            e, train_acc[e], valid_acc[e]))\n\n        #loss가 감소하면 model저장\n        if valid_loss_min > valid_loss[e]:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss[e]))\n            validpoint_B = {'model_state_dict': model_B.state_dict(),\n                  'optimizer_state_dict': optimizer_B.state_dict()}\n\n            torch.save(validpoint_B, 'validpoint_B.pth')\n\n            valid_loss_min = valid_loss[e]","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:51:18.000667Z","iopub.execute_input":"2022-06-16T16:51:18.001082Z","iopub.status.idle":"2022-06-16T17:19:46.501833Z","shell.execute_reply.started":"2022-06-16T16:51:18.001047Z","shell.execute_reply":"2022-06-16T17:19:46.500922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_loss, label='train_loss')\nplt.plot(valid_loss, label='valid_loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T17:19:46.503752Z","iopub.execute_input":"2022-06-16T17:19:46.504594Z","iopub.status.idle":"2022-06-16T17:19:46.83049Z","shell.execute_reply.started":"2022-06-16T17:19:46.504543Z","shell.execute_reply":"2022-06-16T17:19:46.82962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_acc, label='train_acc')\nplt.plot(valid_acc, label='valid_acc')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T17:19:46.835017Z","iopub.execute_input":"2022-06-16T17:19:46.83555Z","iopub.status.idle":"2022-06-16T17:19:47.146501Z","shell.execute_reply.started":"2022-06-16T17:19:46.835511Z","shell.execute_reply":"2022-06-16T17:19:47.145783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 60\n\nvalid_loss_min = np.Inf\nvalid_acc_min = 0\n\ntrain_loss = torch.zeros(n_epochs)\nvalid_loss = torch.zeros(n_epochs)\n\ntrain_acc = torch.zeros(n_epochs)\nvalid_acc = torch.zeros(n_epochs)\n\n\nfor e in range(0, n_epochs):\n        model_C.train()\n        for data, labels in train_loader_C:\n            data, labels = data.to(device), labels.to(device)\n\n            optimizer_C.zero_grad()\n\n            logits = model_C(data)\n            loss = criterion_C(logits, labels)\n            loss.backward()\n            optimizer_C.step()\n\n            train_loss[e] += loss.item()\n\n            ps = F.softmax(logits, dim=1)\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = top_class == labels.reshape(top_class.shape)\n            train_acc[e] += torch.mean(equals.type(torch.float)).item()\n\n        train_loss[e] /= len(train_loader_C)\n        train_acc[e] /= len(train_loader_C)\n\n        with torch.no_grad():\n            model_C.eval()\n            for data, labels in valid_loader_C:\n                data, labels = data.to(device), labels.to(device)\n\n                logits = model_C(data)\n                loss = criterion_C(logits, labels)\n                valid_loss[e] += loss.item()\n\n                ps = F.softmax(logits, dim=1)\n                top_p, top_class = ps.topk(1, dim=1) \n                equals = top_class == labels.reshape(top_class.shape)\n                valid_acc[e] += torch.mean(equals.type(torch.float)).item()\n\n        valid_loss[e] /= len(valid_loader_C)\n        valid_acc[e] /= len(valid_loader_C)\n        scheduler_C.step()\n        \n        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n            e, train_loss[e], valid_loss[e]))\n\n        print('Epoch: {} \\tTraining accuracy: {:.6f} \\tValidation accuracy: {:.6f}'.format(\n            e, train_acc[e], valid_acc[e]))\n\n        #loss가 감소하면 model저장\n        if valid_loss_min > valid_loss[e]:\n            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n            valid_loss_min,\n            valid_loss[e]))\n            validpoint_C = {'model_state_dict': model_C.state_dict(),\n                  'optimizer_state_dict': optimizer_C.state_dict()}\n\n            torch.save(validpoint_C, 'validpoint_C.pth')\n\n            valid_loss_min = valid_loss[e]","metadata":{"execution":{"iopub.status.busy":"2022-06-17T11:42:18.840098Z","iopub.execute_input":"2022-06-17T11:42:18.840511Z","iopub.status.idle":"2022-06-17T12:08:31.093386Z","shell.execute_reply.started":"2022-06-17T11:42:18.840474Z","shell.execute_reply":"2022-06-17T12:08:31.092660Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_loss, label='train_loss')\nplt.plot(valid_loss, label='valid_loss')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:09:54.234124Z","iopub.execute_input":"2022-06-17T12:09:54.234457Z","iopub.status.idle":"2022-06-17T12:09:54.525459Z","shell.execute_reply.started":"2022-06-17T12:09:54.234419Z","shell.execute_reply":"2022-06-17T12:09:54.524834Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"plt.plot(train_acc, label='train_acc')\nplt.plot(valid_acc, label='valid_acc')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:09:56.514316Z","iopub.execute_input":"2022-06-17T12:09:56.514618Z","iopub.status.idle":"2022-06-17T12:09:56.716458Z","shell.execute_reply.started":"2022-06-17T12:09:56.514556Z","shell.execute_reply":"2022-06-17T12:09:56.715799Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"--------------------------","metadata":{"execution":{"iopub.execute_input":"2022-05-02T07:16:33.271344Z","iopub.status.busy":"2022-05-02T07:16:33.271002Z","iopub.status.idle":"2022-05-02T07:16:33.277614Z","shell.execute_reply":"2022-05-02T07:16:33.276446Z","shell.execute_reply.started":"2022-05-02T07:16:33.271298Z"}}},{"cell_type":"markdown","source":"## Step 6: Analyze the  training/validation results\n+ 위에서 구한 학습 결과를 분석합니다. \n+ 수업에서 배운 그래프를 활용하시는 것을 적극 추천드립니다.\n+ 만족할만한 결과가 나올 때 까지 Hyper Parameter Tuning을 진행합니다. ","metadata":{}},{"cell_type":"markdown","source":"### Step6을 Step5에서 함께 했습니다.","metadata":{}},{"cell_type":"code","source":"# plt.plot(train_loss, label='train_loss')\n# plt.plot(valid_loss, label='valid_loss')\n# plt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.plot(train_acc, label='train_acc')\n# plt.plot(valid_acc, label='valid_acc')\n# plt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-06-15T22:37:17.54753Z","iopub.execute_input":"2022-06-15T22:37:17.547829Z","iopub.status.idle":"2022-06-15T22:37:17.553985Z","shell.execute_reply.started":"2022-06-15T22:37:17.547788Z","shell.execute_reply":"2022-06-15T22:37:17.553218Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"--------------------------","metadata":{"execution":{"iopub.execute_input":"2022-05-02T07:16:33.271344Z","iopub.status.busy":"2022-05-02T07:16:33.271002Z","iopub.status.idle":"2022-05-02T07:16:33.277614Z","shell.execute_reply":"2022-05-02T07:16:33.276446Z","shell.execute_reply.started":"2022-05-02T07:16:33.271298Z"}}},{"cell_type":"markdown","source":"## Step 7: Define Test Data Set\n> Test data를 위한 Custom Test Dataset을 제공해드립니다.   \n> 필요한 부분을 채워 사용하시거나 직접 코드를 작성하셔도 됩니다.","metadata":{"execution":{"iopub.execute_input":"2022-04-29T07:02:16.640927Z","iopub.status.busy":"2022-04-29T07:02:16.640238Z","iopub.status.idle":"2022-04-29T07:02:16.644942Z","shell.execute_reply":"2022-04-29T07:02:16.644001Z","shell.execute_reply.started":"2022-04-29T07:02:16.640891Z"}}},{"cell_type":"code","source":"'''Custom Dataset을 제작하기 위해서는 3가지를 반드시 포함해야합니다. \n1.def __init__()      :초기화 함수입니다. Dataset을 상속받아 imagepath와 transform을 지정합니다.\n2.def __len__()       :dataset의 총 길이를 return하는 함수입니다. \n3.def __getitem__()   :index(idx)에 해당하는 data sample을 return 하는 함수입니다. \n'''\nclass test_Dataset(Dataset): #test_set을 class로 정의합니다.\n    def __init__(self,imgpath,transform=None):\n        \n        self.imgpath = imgpath\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.imgpath)\n    \n    def __getitem__(self,idx):\n        if self.transform !=None:\n            x = self.transform(Image.open(self.imgpath[idx]).convert('RGB'))\n        else: x = Image.open(self.imgpath[idx]).convert('RGB')\n        return x","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-06-17T12:10:15.319374Z","iopub.execute_input":"2022-06-17T12:10:15.319663Z","iopub.status.idle":"2022-06-17T12:10:15.326090Z","shell.execute_reply.started":"2022-06-17T12:10:15.319621Z","shell.execute_reply":"2022-06-17T12:10:15.325440Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#예시 코드입니다. 잘 작동하는지 확인해봅시다.\ntest_dir = '../input/2022-deep-learning-basics-challenge/painting_resize_256/test'\ntest_set  = sorted(glob.glob(test_dir+'/*'))\ntest_data = test_Dataset(test_set)\n\n# 잘 불러오는지 확인해 봅시다. \nprint(\"test_data_len:\", test_data.__len__())\ntest_data.__getitem__(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:10:16.069186Z","iopub.execute_input":"2022-06-17T12:10:16.069850Z","iopub.status.idle":"2022-06-17T12:10:16.170188Z","shell.execute_reply.started":"2022-06-17T12:10:16.069774Z","shell.execute_reply":"2022-06-17T12:10:16.169531Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_dir = '../input/2022-deep-learning-basics-challenge/painting_resize_256/test'\n#transforms.Resize(255),\ntest_transform = torchvision.transforms.Compose([\n                                                 transforms.CenterCrop(244),\n                                                 transforms.ToTensor(),\n                                                 transforms.Normalize([meanR, meanG, meanB], [stdR, stdG, stdB])])\n#test_transform 정의 \n\ntest_set  = sorted(glob.glob(test_dir+'/*')) #모든 파일을 읽어서 정리합니다. \ntest_data = test_Dataset(test_set,test_transform)\n\n#Data Loader 작성 , (tip: test이므로 Shuffle을 할 필요가 없습니다. )\ntest_DataLoader = test_loader = torch.utils.data.DataLoader(test_data, batch_size=16)\n\n ","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:10:17.247616Z","iopub.execute_input":"2022-06-17T12:10:17.248128Z","iopub.status.idle":"2022-06-17T12:10:17.260361Z","shell.execute_reply.started":"2022-06-17T12:10:17.248084Z","shell.execute_reply":"2022-06-17T12:10:17.259483Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"----------------","metadata":{}},{"cell_type":"markdown","source":"## Step 8(Final): Predict with Test Data\n### Step 8-1: Predict \n+ test data를 우리의 모델로 예측합니다.","metadata":{}},{"cell_type":"code","source":"#class 재 확인 15개인지 확인하십시오 \nprint('Total Class num: ',class_num)\nprint('Class label:')\nfor i in range(class_num):print('{:5d}th : ' .format(i+1),classes[i])","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:10:18.638886Z","iopub.execute_input":"2022-06-17T12:10:18.639667Z","iopub.status.idle":"2022-06-17T12:10:18.650323Z","shell.execute_reply.started":"2022-06-17T12:10:18.639577Z","shell.execute_reply":"2022-06-17T12:10:18.649404Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"classes = sorted(classes)\nclasses","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:10:19.630972Z","iopub.execute_input":"2022-06-17T12:10:19.631695Z","iopub.status.idle":"2022-06-17T12:10:19.637724Z","shell.execute_reply.started":"2022-06-17T12:10:19.631643Z","shell.execute_reply":"2022-06-17T12:10:19.636858Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# model_A1과 model_A2는 기존에 성능이 좋았던 model_A와 model_B이다.\nmodel_A1 = GNN() \nmodel_A1 = torch.load(\"../input/model-final2/predict_model_A (77.9).pt\")\nmodel_A2 = GNN()\nmodel_A2 = torch.load(\"../input/model-final2/predict_model_B (77.9).pt\")\n\nmodel_A1.to(device)\nmodel_A2.to(device)\n\nmodel_A1.eval()\nmodel_A2.eval()\n\n#model_C만 성능을 계속 개선시키면서 사용중이므로 load_state_dict를 사용했다.\nmodel_C.load_state_dict(validpoint_C['model_state_dict'])\nmodel_C.eval()\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:10:34.682868Z","iopub.execute_input":"2022-06-17T12:10:34.683566Z","iopub.status.idle":"2022-06-17T12:10:35.489994Z","shell.execute_reply.started":"2022-06-17T12:10:34.683527Z","shell.execute_reply":"2022-06-17T12:10:35.489249Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"pred = []  \n\n#test_loader = iter(test_DataLoader)\n# 최종적으로 예측한 각 sample의 label을 담아 놓을 list입니다.  \n#0~14까지 우리가 예측한 가장 높은 확률의 label이 들어가면 되겠죠? \nfor data in test_DataLoader:\n    data = data.to(device)\n    logits_A = model_A1(data)\n    logits_B = model_A2(data)\n    logits_C = model_C(data)\n    logits = (logits_A+logits_B+logits_C)/3\n    ps = F.softmax(logits, dim=1)\n    _, top_class = ps.topk(1, dim=1)\n    for i in range(len(data)):\n        pred.append(top_class[i].item())\n        \n#모델 3개가 각각 예측을 한 후 평균 값을 구해서 대입한다.","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:10:36.860517Z","iopub.execute_input":"2022-06-17T12:10:36.860805Z","iopub.status.idle":"2022-06-17T12:10:46.478625Z","shell.execute_reply.started":"2022-06-17T12:10:36.860775Z","shell.execute_reply":"2022-06-17T12:10:46.477849Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Step 8-2 : Making csv file with our predict result\n+ csv파일로 만드는 예시를 보여드립니다. ","metadata":{}},{"cell_type":"code","source":"name=[]                                     # 그림의 Id를 담을 list 생성 \ncategory =[]                                # 그림의 Category를 담을 list 생성\nfor i in range(test_data.__len__()):        #\n    name.append(test_set[i].split('/')[-1]) # 파일 이름에서 label만 가지고 옵니다. \n    category.append(classes[pred[i]])       # pred에 해당하는 class를 category에 집어 넣습니다. \n    \n    \ntm = localtime()\ncsv_file_name = f\"{tm.tm_mday}day_{tm.tm_hour}h_{tm.tm_min}m_{tm.tm_sec}s\"\n\n#파일의 이름은 마음대로 설정할 수 있습니다. 경로를 쓰지 않으면 현재 디렉토리에 알아서 생성됩니다. \npd.DataFrame({'Id':name,'Category':category}).to_csv(f'predict_{\"ff\"}.csv',index=False)    \n\n#predict 하기 위해서 model 전체를 저장합니다. 체점을 위해서 필요한 과정입니다.\n# torch.save(model_A,f'./predict_{\"model_A\"}.pt')                                                  \n# torch.save(model_B,f'./predict_{\"model_B\"}.pt')\ntorch.save(model_C,f'./predict_{\"model_C\"}.pt')","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:11:24.747471Z","iopub.execute_input":"2022-06-17T12:11:24.748065Z","iopub.status.idle":"2022-06-17T12:11:25.122181Z","shell.execute_reply.started":"2022-06-17T12:11:24.748025Z","shell.execute_reply":"2022-06-17T12:11:25.121447Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"print(name[:5])\nprint(category[:5])","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:11:26.154042Z","iopub.execute_input":"2022-06-17T12:11:26.154728Z","iopub.status.idle":"2022-06-17T12:11:26.160068Z","shell.execute_reply.started":"2022-06-17T12:11:26.154690Z","shell.execute_reply":"2022-06-17T12:11:26.159274Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# 잘 생성됬는지 확인 , 따로 경로를 설정하지 않았다면,현재 디렉토리에 자동으로 생성됩니다. \ndf= pd.read_csv(f'./predict_{\"ff\"}.csv')\ndf.head(30) #앞부분 더 확인해 보고싶어서 30으로 늘렸다.","metadata":{"execution":{"iopub.status.busy":"2022-06-17T12:11:44.021547Z","iopub.execute_input":"2022-06-17T12:11:44.022267Z","iopub.status.idle":"2022-06-17T12:11:44.048329Z","shell.execute_reply.started":"2022-06-17T12:11:44.022231Z","shell.execute_reply":"2022-06-17T12:11:44.047531Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"## 생성한 csv파일을 kaggle에 등록하시면 됩니다.\n\n","metadata":{}}]}